"""
chatbot_google_studio_repl_updated.py
Phi√™n b·∫£n REPL n√¢ng cao: k·∫øt h·ª£p t√¨m ki·∫øm tr√™n nhi·ªÅu c·ªôt (title, content, tags, region)
v√† ch·∫°y li√™n t·ª•c (REPL). D√πng Google Studio AI (Gemini-pro) ƒë·ªÉ tr·∫£ l·ªùi.

H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:
1) C√†i th∆∞ vi·ªán:
   pip install pandas rapidfuzz requests

2) M·ªü file v√† ƒëi·ªÅn API key v√†o bi·∫øn API_KEY b√™n d∆∞·ªõi (thay "YOUR_GOOGLE_API_KEY_HERE").

3) ƒê·∫∑t file CSV `south_vn_travel.csv` trong c√πng th∆∞ m·ª•c (m·∫´u c√≥ s·∫µn).

4) Ch·∫°y:
   python chatbot_google_studio_repl_updated.py

G√µ 'exit' ho·∫∑c 'quit' ƒë·ªÉ tho√°t ch∆∞∆°ng tr√¨nh.
"""

import time, json
import pandas as pd
from rapidfuzz import process, fuzz
from collections import defaultdict
import requests

# ========== ƒêI·ªÄN API KEY ·ªû ƒê√ÇY ==========
API_KEY = "AIzaSyDjldtlqP2r6MzCc0HJkUvkdJeP2G0H-BA"  # <-- Thay b·∫±ng key th·∫≠t
# =======================================

MODEL = "gemini-2.5-flash"
URL = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL}:generateContent"
CSV_PATH = "./south_vn_travel.csv"

# --- Search ---
def combined_search(query, df, top_k=6):
    """
    K·∫øt h·ª£p fuzzy search tr√™n title, content, tags v√† boost theo region.
    Tr·∫£ v·ªÅ danh s√°ch dict: {'index','score','row'} s·∫Øp x·∫øp theo score gi·∫£m d·∫ßn.
    """
    titles = df['title'].astype(str).tolist() if 'title' in df.columns else ['']*len(df)
    contents = df['content'].astype(str).tolist() if 'content' in df.columns else ['']*len(df)
    tags = df['tags'].astype(str).tolist() if 'tags' in df.columns else ['']*len(df)
    regions = df['region'].astype(str).tolist() if 'region' in df.columns else ['']*len(df)

    # Compute fuzzy matches for each field (full lists)
    title_matches = process.extract(query, titles, scorer=fuzz.WRatio, limit=len(titles))
    content_matches = process.extract(query, contents, scorer=fuzz.WRatio, limit=len(contents))
    tag_matches = process.extract(query, tags, scorer=fuzz.WRatio, limit=len(tags))

    score_map = defaultdict(float)
    # weights
    w_title, w_content, w_tag, w_region_boost = 0.6, 0.25, 0.15, 25.0

    for text, score, idx in title_matches:
        score_map[idx] += w_title * (score / 100.0)
    for text, score, idx in content_matches:
        score_map[idx] += w_content * (score / 100.0)
    for text, score, idx in tag_matches:
        score_map[idx] += w_tag * (score / 100.0)

    q_lower = query.lower()
    # boost by region mentions in query (exact substring match, case-insensitive)
    for idx, reg in enumerate(regions):
        try:
            if isinstance(reg, str) and reg.strip() and reg.lower() in q_lower:
                score_map[idx] += w_region_boost
        except Exception:
            continue

    # If nothing scored (all zero), fallback to simple region/tag filters or top rows
    if not any(score_map.values()):
        # try region filter: look for any region token in query that matches df['region']
        candidate_idxs = []
        for idx, reg in enumerate(regions):
            if isinstance(reg, str) and reg.strip() and reg.lower() in q_lower:
                candidate_idxs.append(idx)
        if not candidate_idxs:
            # try tag matching via simple substring
            for idx, t in enumerate(tags):
                if isinstance(t, str) and any(tok in q_lower for tok in t.lower().split(',')):
                    candidate_idxs.append(idx)
        if not candidate_idxs:
            candidate_idxs = list(range(min(len(df), top_k)))
        for i in candidate_idxs:
            score_map[i] += 1.0

    # Normalize/convert to 0..100-like scores and sort
    scored = [(idx, val) for idx, val in score_map.items()]
    scored.sort(key=lambda x: x[1], reverse=True)
    results = []
    for idx, raw in scored[:top_k]:
        results.append({
            "index": int(idx),
            "score": float(raw * 100),  # map back to 0..100-ish
            "row": df.iloc[idx].to_dict()
        })
    return results


# --- Prompt builder ---
def build_prompt(question, hits, include_history=None):
    context_parts = []
    for i, h in enumerate(hits, start=1):
        r = h["row"]
        context_parts.append(
            f"{i}. {r.get('title')} ({r.get('region')}): {r.get('short_description')} -- {r.get('address')}"
        )
    context_text = "\n".join(context_parts)
    history_text = ""
    if include_history:
        history_text = "\n\nL·ªãch s·ª≠ (ng·∫Øn):\n" + "\n".join(include_history[-6:])
    prompt = (
        f"D∆∞·ªõi ƒë√¢y l√† th√¥ng tin tham kh·∫£o v·ªÅ du l·ªãch mi·ªÅn Nam Vi·ªát Nam:\n{context_text}\n"
        f"{history_text}\n\nH·ªèi: {question}\nTr·∫£ l·ªùi ng·∫Øn g·ªçn b·∫±ng ti·∫øng Vi·ªát, n√™u t√™n ƒë·ªãa ƒëi·ªÉm, 1 c√¢u m√¥ t·∫£ v√† ƒë·ªãa ch·ªâ. N·∫øu kh√¥ng ƒë·ªß th√¥ng tin, ghi 'Kh√¥ng ƒë·ªß th√¥ng tin'."
    )
    return prompt


# --- API call ---
def ask_gemini(prompt):
    headers = {
        "Content-Type": "application/json",
        "x-goog-api-key": API_KEY,
    }
    body = {"contents": [{"parts": [{"text": prompt}]}]}
    resp = requests.post(URL, headers=headers, json=body, timeout=30)
    resp.raise_for_status()
    data = resp.json()
    try:
        return data["candidates"][0]["content"]["parts"][0]["text"]
    except Exception:
        return json.dumps(data, ensure_ascii=False, indent=2)


# --- Main REPL ---
def load_data(path=CSV_PATH):
    try:
        return pd.read_csv(path)
    except FileNotFoundError:
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y {path}. H√£y ƒë·∫∑t file CSV c√πng th∆∞ m·ª•c.")
        raise

def main():
    if "YOUR_GOOGLE_API_KEY_HERE" in API_KEY or not API_KEY.strip():
        print("‚ö†Ô∏è B·∫°n ch∆∞a ƒëi·ªÅn API key! M·ªü file v√† ƒëi·ªÅn key v√†o bi·∫øn API_KEY.")
        return

    try:
        df = load_data()
    except FileNotFoundError:
        return

    print(f"‚úÖ ƒê√£ t·∫£i {len(df)} ƒë·ªãa ƒëi·ªÉm t·ª´ {CSV_PATH}.")
    print("G√µ 'exit' ho·∫∑c 'quit' ƒë·ªÉ tho√°t.\n")

    history = []

    while True:
        try:
            question = input("B·∫°n h·ªèi: ").strip()
            if not question:
                print("Nh·∫≠p c√¢u h·ªèi (kh√¥ng ƒë·ªÉ tr·ªëng) ho·∫∑c 'exit' ƒë·ªÉ tho√°t.")
                continue
            if question.lower() in ("exit", "quit"):
                print("Tho√°t ch∆∞∆°ng tr√¨nh. Bye!")
                break

            # Use combined_search (many fields)
            hits = combined_search(question, df, top_k=6)

            # If user mentions a region explicitly, ensure we include all rows from that region (no duplicates)
            q_lower = question.lower()
            # Try match common variants for 'C·∫ßn Th∆°' etc.
            for region in df['region'].unique():
                try:
                    if isinstance(region, str) and region.strip() and region.lower() in q_lower:
                        region_rows = df[df['region'].str.lower().str.contains(region.lower(), na=False)]
                        extra = []
                        for i, row in region_rows.iterrows():
                            if not any(h['index'] == i for h in hits):
                                extra.append({"index": int(i), "score": 90.0, "row": row.to_dict()})
                        # prepend region-specific results so they appear first
                        hits = extra + hits
                except Exception:
                    continue

            # Build prompt with top 3 context rows
            prompt = build_prompt(question, hits[:3], include_history=history)

            print("\n--- Prompt (preview) ---")
            print(prompt if len(prompt) < 1200 else prompt[:1200] + "\n...[truncated]")

            try:
                answer = ask_gemini(prompt)
            except requests.exceptions.RequestException as e:
                print(f"‚ö†Ô∏è L·ªói khi g·ªçi API: {e}")
                print("Th·ª≠ l·∫°i sau 2s...")
                time.sleep(2)
                continue

            print("\nüí¨ AI tr·∫£ l·ªùi:")
            print("-" * 60)
            print(answer)
            print("-" * 60)

            history.append(f"Q: {question}")
            history.append(f"A: {answer[:200]}")
            if len(history) > 40:
                history = history[-40:]

        except KeyboardInterrupt:
            print("\nNh·∫≠n SIGINT ‚Äî tho√°t ch∆∞∆°ng tr√¨nh. Bye!")
            break
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói kh√¥ng mong mu·ªën: {e}")
            time.sleep(0.5)
            continue


if __name__ == "__main__":
    main()
